{
  "name": "LTX-2_T2V_Full_wLora",
  "description": "Converted LTX-2 workflow",
  "version": 0.4,
  "workflow": {
    "5232": {
      "class_type": "EmptyImage",
      "inputs": {
        "width": 1920,
        "height": 1088,
        "batch_size": 1,
        "color": 0
      }
    },
    "5236": {
      "class_type": "PrimitiveFloat",
      "inputs": {
        "value": 24
      }
    },
    "5220": {
      "class_type": "CheckpointLoaderSimple",
      "inputs": {
        "ckpt_name": "ltx-2-19b-dev.safetensors"
      }
    },
    "5219": {
      "class_type": "LTXVAudioVAELoader",
      "inputs": {
        "ckpt_name": "ltx-2-19b-dev.safetensors"
      }
    },
    "5075": {
      "class_type": "SaveVideo",
      "inputs": {
        "video": [
          5223,
          0
        ],
        "filename_prefix": "auto",
        "format": "auto"
      }
    },
    "5229": {
      "class_type": "LTXVConditioning",
      "inputs": {
        "positive": [
          5228,
          0
        ],
        "negative": [
          5226,
          0
        ],
        "frame_rate": [
          5236,
          0
        ]
      }
    },
    "5228": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "clip": [
          5218,
          0
        ],
        "text": [
          5227,
          0
        ]
      }
    },
    "5221": {
      "class_type": "LoraLoaderModelOnly",
      "inputs": {
        "model": [
          5216,
          0
        ],
        "lora_name": 1
      }
    },
    "5222": {
      "class_type": "LoraLoaderModelOnly",
      "inputs": {
        "model": [
          5220,
          0
        ],
        "lora_name": 1
      }
    },
    "5226": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "clip": [
          5218,
          0
        ],
        "text": "blurry, low quality, still frame, frames, watermark, overlay, titles, has blurbox, has subtitles"
      }
    },
    "5270": {
      "class_type": "LatentUpscaleModelLoader",
      "inputs": {
        "model_name": "ltx-2-spatial-upscaler-x2-1.0.safetensors"
      }
    },
    "5227": {
      "class_type": "LTXVGemmaEnhancePrompt",
      "inputs": {
        "clip": [
          5218,
          0
        ],
        "image": "randomize",
        "prompt": [
          5225,
          0
        ],
        "system_prompt": 512,
        "max_tokens": true,
        "bypass_i2v": 2793143611
      }
    },
    "5225": {
      "class_type": "PrimitiveStringMultiline",
      "inputs": {
        "value": "cinematic drama movie scene shows a closeup of a blonde woman wearing a red sweater hanging out of the open door of a moving train, looking outside and smiling. the camera is fixed to the train's side as the train moves forward on the track. the woman seems excited and says: \" I think we're almost there!\". we hear the train's engine in the background. then, a little boy with brown hair pops his head out of the train along with the woman, looking at her in excitement. he then asks her: \"This is Nana's old village, isn't it?\". she nodes and embraces him joyfully."
      }
    },
    "5233": {
      "class_type": "PrimitiveInt",
      "inputs": {
        "value": 241
      }
    },
    "5223": {
      "class_type": "CreateVideo",
      "inputs": {
        "images": [
          5293,
          0
        ],
        "audio": [
          5294,
          0
        ],
        "fps": [
          5236,
          0
        ]
      }
    },
    "5216": {
      "class_type": "LoraLoaderModelOnly",
      "inputs": {
        "model": [
          5220,
          0
        ],
        "lora_name": 0.6
      }
    },
    "5276": {
      "class_type": "LTXVSeparateAVLatent",
      "inputs": {
        "av_latent": [
          5282,
          1
        ]
      }
    },
    "5277": {
      "class_type": "EmptyLTXVLatentVideo",
      "inputs": {
        "width": [
          5280,
          0
        ],
        "height": [
          5280,
          1
        ],
        "length": [
          5233,
          0
        ],
        "batch_size": 1
      }
    },
    "5278": {
      "class_type": "ImageScaleBy",
      "inputs": {
        "image": [
          5232,
          0
        ],
        "upscale_method": 0.5
      }
    },
    "5279": {
      "class_type": "LTXVEmptyLatentAudio",
      "inputs": {
        "audio_vae": [
          5219,
          0
        ],
        "frames_number": [
          5233,
          0
        ],
        "frame_rate": [
          5236,
          0
        ],
        "batch_size": 1
      }
    },
    "5280": {
      "class_type": "GetImageSize",
      "inputs": {
        "image": [
          5278,
          0
        ]
      }
    },
    "5281": {
      "class_type": "LTXVConcatAVLatent",
      "inputs": {
        "video_latent": [
          5277,
          0
        ],
        "audio_latent": [
          5279,
          0
        ]
      }
    },
    "5282": {
      "class_type": "SamplerCustomAdvanced",
      "inputs": {
        "noise": [
          5284,
          0
        ],
        "guider": [
          5283,
          0
        ],
        "sampler": [
          5287,
          0
        ],
        "sigmas": [
          5285,
          0
        ],
        "latent_image": [
          5286,
          0
        ]
      }
    },
    "5283": {
      "class_type": "CFGGuider",
      "inputs": {
        "model": [
          5221,
          0
        ],
        "positive": [
          5229,
          0
        ],
        "negative": [
          5229,
          1
        ]
      }
    },
    "5284": {
      "class_type": "RandomNoise",
      "inputs": {
        "noise_seed": 420
      }
    },
    "5285": {
      "class_type": "ManualSigmas",
      "inputs": {
        "sigmas": "0.909375, 0.725, 0.421875, 0.0"
      }
    },
    "5286": {
      "class_type": "LTXVConcatAVLatent",
      "inputs": {
        "video_latent": [
          5296,
          0
        ],
        "audio_latent": [
          5291,
          1
        ]
      }
    },
    "5287": {
      "class_type": "KSamplerSelect",
      "inputs": {
        "sampler_name": "res_2s"
      }
    },
    "5288": {
      "class_type": "CFGGuider",
      "inputs": {
        "model": [
          5222,
          0
        ],
        "positive": [
          5229,
          0
        ],
        "negative": [
          5229,
          1
        ]
      }
    },
    "5289": {
      "class_type": "LTXVScheduler",
      "inputs": {
        "latent": [
          5281,
          0
        ],
        "steps": 20,
        "max_shift": 2.05,
        "base_shift": 0.95,
        "stretch": true,
        "terminal": 0.1
      }
    },
    "5290": {
      "class_type": "KSamplerSelect",
      "inputs": {
        "sampler_name": "res_2s"
      }
    },
    "5291": {
      "class_type": "LTXVSeparateAVLatent",
      "inputs": {
        "av_latent": [
          5292,
          1
        ]
      }
    },
    "5292": {
      "class_type": "SamplerCustomAdvanced",
      "inputs": {
        "noise": [
          5295,
          0
        ],
        "guider": [
          5288,
          0
        ],
        "sampler": [
          5290,
          0
        ],
        "sigmas": [
          5289,
          0
        ],
        "latent_image": [
          5281,
          0
        ]
      }
    },
    "5293": {
      "class_type": "LTXVSpatioTemporalTiledVAEDecode",
      "inputs": {
        "vae": [
          5220,
          2
        ],
        "latents": [
          5276,
          0
        ],
        "spatial_tiles": 16,
        "spatial_overlap": 4,
        "temporal_tile_length": false,
        "temporal_overlap": "auto",
        "last_frame_fix": "auto"
      }
    },
    "5294": {
      "class_type": "LTXVAudioVAEDecode",
      "inputs": {
        "samples": [
          5276,
          1
        ],
        "audio_vae": [
          5219,
          0
        ]
      }
    },
    "5295": {
      "class_type": "RandomNoise",
      "inputs": {
        "noise_seed": 43
      }
    },
    "5296": {
      "class_type": "LTXVLatentUpsampler",
      "inputs": {
        "samples": [
          5291,
          0
        ],
        "upscale_model": [
          5270,
          0
        ],
        "vae": [
          5220,
          2
        ]
      }
    },
    "5218": {
      "class_type": "LTXVGemmaCLIPModelLoader",
      "inputs": {
        "gemma_path": "gemma-3-12b-it-qat-q4_0-unquantized/model-00001-of-00005.safetensors",
        "ltxv_path": "ltx-2-19b-dev.safetensors",
        "max_length": 1024
      }
    }
  }
}